# kafka

**What is kafka**

Apache Kafka is a distributed data store optimized for ingesting and processing streaming data in real-time. Streaming data is data that is continuously generated by thousands of data sources, which typically send the data records in simultaneously. A streaming platform needs to handle this constant influx of data, and process the data sequentially and incrementally.

**What is zookeeper?**

ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications

Repo clonated from `https://github.com/conduktor/kafka-stack-docker-compose.git`

## Run kafka

Run the following command:
```bash
sudo docker compose -f zk-single-kafka-single.yml up --build
```

Test if the deploy was successful:
```bash
sudo docker exec -it kafka1 bash
[appuser@kafka1 ~]$ kafka-topics --version
```

## kafkactl

To interact with kafka from the command line, you need to install kafkactl

## Consume a topic
```bash
kafkactl consume test-topic
```
You can also consume from the beginning:
```bash
kafkactl consume test-topic --from-beginning
```

## Produce a topic
```bash
kafkactl produce test-topic --key=test-key --value=test-value
```
You can produce content with json data of any size.
